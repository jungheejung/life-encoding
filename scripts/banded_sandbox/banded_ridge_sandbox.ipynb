{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib; matplotlib.use('agg')\n",
    "import mvpa2.suite as mv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.io import wavfile\n",
    "import sys, os, time, csv\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from nilearn.plotting import plot_surf\n",
    "import matplotlib.pyplot as plt\n",
    "from tikreg import models\n",
    "from tikreg import utils as tikutils\n",
    "\n",
    "from tikreg import models, utils as tikutils\n",
    "from tikreg import spatial_priors, temporal_priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [7., 7.]\n",
    "matplotlib.rcParams['font.size'] = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = ['sub-rid000001']\n",
    "hemispheres = ['lh']\n",
    "\n",
    "tr_movie = {1:369, 2:341, 3:372, 4:406}\n",
    "tr_fmri = {1:374, 2:346, 3:377, 4:412}\n",
    "tr_length = 2.5\n",
    "n_samples = 1509\n",
    "n_vertices = 40962\n",
    "n_proc = 32     # how many cores do we have?\n",
    "n_medial = {'lh': 3486, 'rh': 3491}\n",
    "\n",
    "# mvpa_dir = '/idata/DBIC/cara/life/pymvpa/'\n",
    "sam_data_dir = '/Users/h/Documents/projects_local/life-encoding-sandbox/data'\n",
    "# ridge_dir = '/idata/DBIC/cara/life/ridge'\n",
    "# cara_data_dir = '/idata/DBIC/cara/life/data'\n",
    "npy_dir = '/Users/h/Documents/projects_local/life-encoding-sandbox/w2v_features'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_stim_for_fold(stimfile, fold_shifted, included):\n",
    "    cam = np.load(os.path.join(npy_dir, '{0}.npy'.format(stimfile)))\n",
    "    # motion = np.load('/ihome/cara/global_motion/motion_downsampled_complete.npy')\n",
    "    #\n",
    "    # motion_list = []\n",
    "    # motion_list.append(motion[:369])\n",
    "    # motion_list.append(motion[369:710])\n",
    "    # motion_list.append(motion[710:1082])\n",
    "    # motion_list.append(motion[1082:])\n",
    "\n",
    "    full_stim = []\n",
    "    full_stim.append(cam[:369,:])\n",
    "    full_stim.append(cam[369:710,:])\n",
    "    full_stim.append(cam[710:1082,:])\n",
    "    full_stim.append(cam[1082:,:])\n",
    "\n",
    "    for i in range(len(full_stim)):\n",
    "        # m = motion_list[i]\n",
    "    \t# m_avg = np.mean(np.vstack((m[3:], m[2:-1], m[1:-2], m[:-3])),axis=0)\n",
    "    \t# m_avg = np.reshape(m_avg,(-1,1))\n",
    "\n",
    "        this = full_stim[i]\n",
    "        # full_stim[i] = np.concatenate((m_avg, this[3:,:], this[2:-1,:], this[1:-2,:], this[:-3,:]), axis=1)\n",
    "        full_stim[i] = np.concatenate((this[3:,:], this[2:-1,:], this[1:-2,:], this[:-3,:]), axis=1)\n",
    "\n",
    "    train_stim = [full_stim[i] for i in np.subtract(included, 1)]\n",
    "    test_stim = full_stim[fold_shifted-1]\n",
    "\n",
    "    return train_stim, test_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel():\n",
    "    mel_list = [[],[],[],[]]\n",
    "    directory = os.path.join(cara_data_dir, 'spectral', 'complete')\n",
    "    for f in os.listdir(directory):\n",
    "        if 'csv' in f:\n",
    "            run = int(f[-5])\n",
    "            s = pd.read_csv(os.path.join(directory, f))\n",
    "            filter_col = [col for col in s if col.startswith('mel')]\n",
    "            tr_s = np.array(s[filter_col])\n",
    "            tr_avg = np.mean(tr_s, axis=1)\n",
    "\n",
    "            groupby = tr_avg.shape[0] / tr_movie[run]\n",
    "            remainder = tr_avg.shape[0] % tr_movie[run]\n",
    "            tr_reshaped = np.reshape(tr_avg[:-remainder], (tr_movie[run], groupby))\n",
    "            avg = np.mean(tr_reshaped, axis=1)\n",
    "            mel_list[run-1] = avg\n",
    "    return mel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ws_data(test_p, fold_shifted, included, hemi):\n",
    "    print('\\nLoading fMRI GIFTI data for HA in test subj space and using {0} as test participant...'.format(test_p))\n",
    "    train_resp = []\n",
    "    for run in included:\n",
    "        avg = []\n",
    "        if run == 4:\n",
    "            resp = mv.gifti_dataset(os.path.join(sam_data_dir, '{0}_task-life_acq-{1}vol_run-0{2}.{3}.tproject.gii'.format(test_p, tr_fmri[run], run, hemi))).samples[4:-5,:]\n",
    "        else:\n",
    "            resp = mv.gifti_dataset(os.path.join(sam_data_dir, '{0}_task-life_acq-{1}vol_run-0{2}.{3}.tproject.gii'.format(test_p, tr_fmri[run], run, hemi))).samples[4:-4,:]\n",
    "\n",
    "        resp = resp[:,cortical_vertices[hemi] == 1]\n",
    "        mv.zscore(resp, chunks_attr=None)\n",
    "        print('train', run, resp.shape)\n",
    "\n",
    "        train_resp.append(resp)\n",
    "\n",
    "    if fold_shifted == 4:\n",
    "        test_resp = mv.gifti_dataset(os.path.join(sam_data_dir, '{0}_task-life_acq-{1}vol_run-0{2}.{3}.tproject.gii'.format(test_p, tr_fmri[fold_shifted], fold_shifted, hemi))).samples[4:-5,:]\n",
    "    else:\n",
    "        test_resp = mv.gifti_dataset(os.path.join(sam_data_dir, '{0}_task-life_acq-{1}vol_run-0{2}.{3}.tproject.gii'.format(test_p, tr_fmri[fold_shifted], fold_shifted, hemi))).samples[4:-4,:]\n",
    "\n",
    "    test_resp = test_resp[:,cortical_vertices[hemi] == 1]\n",
    "    mv.zscore(test_resp, chunks_attr=None)\n",
    "    print('test', fold_shifted, test_resp.shape)\n",
    "\n",
    "    return train_resp, test_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'visual'\n",
    "align = 'ws'\n",
    "# stimfile = 'all'\n",
    "fold = 1\n",
    "fold_shifted = fold+1\n",
    "hemi = 'lh'\n",
    "included = [1,2,3,4]\n",
    "included.remove(fold_shifted)\n",
    "test_p = 'sub-rid000001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/mvpa2/support/nibabel/afni_niml.py:182: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  data_1d = np.fromstring(s, dtype=tp)\n"
     ]
    }
   ],
   "source": [
    "cortical_vertices = {}\n",
    "for half in ['lh', 'rh']:\n",
    "    test_ds = mv.niml.read('/Users/h/Documents/projects_local/life-encoding-sandbox/niml/ws.lh.niml.dset'.format(half))\n",
    "    cortical_vertices[half] = np.ones((n_vertices))\n",
    "    cortical_vertices[half][np.sum(test_ds.samples[1:, :] != 0, axis=0) == 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features bg & action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading fMRI GIFTI data for HA in test subj space and using sub-rid000001 as test participant...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/mvpa2/datasets/gifti.py:77: DeprecationWarning: giftiio.read function deprecated. Use nibabel.load() instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  samples = giftiio.read(samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train', 1, (366, 37476))\n",
      "('train', 3, (369, 37476))\n",
      "('train', 4, (403, 37476))\n",
      "('test', 2, (338, 37476))\n"
     ]
    }
   ],
   "source": [
    "stimfile = 'bg'\n",
    "X1train_stim, X1test_stim = get_visual_stim_for_fold('{0}_{1}'.format(model, stimfile), fold_shifted, included)\n",
    "\n",
    "stimfile = 'actions'\n",
    "X2train_stim, X2test_stim = get_visual_stim_for_fold('{0}_{1}'.format(model, stimfile), fold_shifted, included)\n",
    "\n",
    "Ytrain_uncon, Ytest = get_ws_data(test_p, fold_shifted, included, hemi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1138, 1200), 'X1train')\n",
      "((1138, 1200), 'X2train')\n",
      "((338, 1200), 'X1test_stim')\n",
      "((338, 1200), 'X2test_stim')\n",
      "((338, 37476), 'Ytest')\n",
      "((1138, 37476), 'Ytrain')\n"
     ]
    }
   ],
   "source": [
    "# concatenate 3 runs\n",
    "X1train = np.concatenate(X1train_stim)\n",
    "X2train = np.concatenate(X2train_stim)\n",
    "\n",
    "Ytrain = np.concatenate(Ytrain_uncon)\n",
    "\n",
    "print(X1train.shape, \"X1train\" )\n",
    "print(X2train.shape, \"X2train\")\n",
    "print(X1test_stim.shape, \"X1test_stim\")\n",
    "print(X2test_stim.shape, \"X2test_stim\")\n",
    "print(Ytest.shape, \"Ytest\")\n",
    "print(Ytrain.shape, \"Ytrain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tikreg - one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77.84183577448114, 4.6415888336127775, 2.51188643150958, 0.5290310600635536, 2.455544661025322)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sampling in terms of ratios and scalings\n",
    "alphas = np.logspace(0,4,11)\n",
    "ratios = np.logspace(-2,2,25)\n",
    "\n",
    "# Solve for one hyperparameter set only\n",
    "# We will use this solution to test the tikreg implementation\n",
    "ratio = ratios[16]\n",
    "alpha = alphas[1]\n",
    "\n",
    "angle = np.arctan(ratio)\n",
    "lambda_one = np.cos(angle)*alpha\n",
    "lambda_two = np.sin(angle)*alpha\n",
    "\n",
    "\n",
    "bands = np.asarray([lambda_one]*X1train.shape[1] + [lambda_two]*X2train.shape[1])\n",
    "Cinv = np.diag(bands**-1)\n",
    "\n",
    "A = np.hstack([X1train/lambda_one, X2train/lambda_two])\n",
    "U, S, VT = np.linalg.svd(A, full_matrices=False)\n",
    "V = VT.T\n",
    "UTY = np.dot(U.T, Ytrain)\n",
    "D = np.diag(S / (S**2 + alpha**2))\n",
    "\n",
    "solution_svd_standard = np.linalg.multi_dot([V, D, UTY])*alpha\n",
    "solution_svd_bandstd2tik = np.dot(Cinv, solution_svd_standard)\n",
    "\n",
    "print(np.rad2deg(angle), ratio, alpha, lambda_one, lambda_two)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tikreg to find the solution\n",
    "X1_prior = spatial_priors.SphericalPrior(X1train, hyparams=[lambda_one])\n",
    "X2_prior = spatial_priors.SphericalPrior(X2train, hyparams=[lambda_two])\n",
    "# A temporal prior is unnecessary, so we specify no delays\n",
    "temporal_prior = temporal_priors.SphericalPrior(delays=[0]) # no delays\n",
    "\n",
    "fit_banded_polar = models.estimate_stem_wmvnp([X1train, X2train], Ytrain,\n",
    "                                              [X1test_stim, X2test_stim],Ytest,\n",
    "                                              feature_priors=[X1_prior, X2_prior],\n",
    "                                              temporal_prior=temporal_prior,\n",
    "                                              ridges=[alpha],\n",
    "                                              folds=(1,5), # 1x 5-fold cross-validation\n",
    "                                              performance=True,\n",
    "                                              weights=True,\n",
    "                                              verbosity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37476, 4)\n"
     ]
    }
   ],
   "source": [
    "voxelwise_optimal_hyperparameters = fit_banded_polar['optima']\n",
    "print(voxelwise_optimal_hyperparameters.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# voxelwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxelwise\n",
    "alphas = voxelwise_optimal_hyperparameters[:,-1]\n",
    "lambda_ones = voxelwise_optimal_hyperparameters[:,1]\n",
    "lambda_twos = voxelwise_optimal_hyperparameters[:,2]\n",
    "kernel_weights = fit_banded_polar['weights']\n",
    "weights_x1 = np.linalg.multi_dot([X1train.T, kernel_weights, np.diag(alphas), np.diag(lambda_ones**-2)])\n",
    "weights_x2 = np.linalg.multi_dot([X2train.T, kernel_weights, np.diag(alphas), np.diag(lambda_twos**-2)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_df = pd.DataFrame(data = Ytest)\n",
    "estimated_x1 = pd.DataFrame(data = weights_x1)\n",
    "estimated_x2 = pd.DataFrame(data = weights_x2)\n",
    "corr_x1 = pd.DataFrame.corrwith(estimated_x1, actual_df, axis = 0, method = 'pearson')\n",
    "corr_x2 = pd.DataFrame.corrwith(estimated_x2, actual_df, axis = 0, method = 'pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save niml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/mvpa2/support/nibabel/afni_niml_types.py:78: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.string_ == np.dtype(str).type`.\n",
      "  (np.issubdtype(data.dtype, np.str) or data.dtype.kind in 'US')\n",
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/mvpa2/support/nibabel/afni_niml_types.py:69: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return type(data) is np.ndarray and np.issubdtype(data.dtype, float)\n",
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/mvpa2/support/nibabel/afni_niml_types.py:65: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  return type(data) is np.ndarray and np.issubdtype(data.dtype, int)\n"
     ]
    }
   ],
   "source": [
    "med_wall_ind = np.where(cortical_vertices[hemi] == 0)[0]\n",
    "out = np.zeros((corr_x1.shape[0]+med_wall_ind.shape[0]),dtype=np.dtype(corr_x1).type)\n",
    "out[cortical_vertices[hemi] == 1] =corr_x1\n",
    "mv.niml.write('/Users/h/Documents/projects_local/life-encoding-sandbox/X1_bg.niml.dset', out[None,:])\n",
    "\n",
    "out = np.zeros((corr_x2.shape[0]+med_wall_ind.shape[0]),dtype=np.dtype(corr_x2).type)\n",
    "out[cortical_vertices[hemi] == 1] =corr_x2\n",
    "mv.niml.write('/Users/h/Documents/projects_local/life-encoding-sandbox/X2_actions.niml.dset', out[None,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "surface_dir = '/Users/h/suma-fsaverage6'\n",
    "sandbox_dir = '/Users/h/Documents/projects_local/life-encoding-sandbox'\n",
    "fsaverage_gii_L = os.path.join(surface_dir ,  'lh.pial.gii')\n",
    "fsaverage_gii_R = os.path.join(surface_dir , 'rh.pial.gii')\n",
    "fsaverage_inflated_L = os.path.join(surface_dir , 'lh.inf_50.gii')\n",
    "fsaverage_inflated_R = os.path.join(surface_dir , 'rh.inf_50.gii')\n",
    "\n",
    "sub_file_name = os.path.join(sandbox_dir, 'X1_bg.niml.dset')\n",
    "X1 = mv.niml.read(sub_file_name)\n",
    "\n",
    "X2_file_name = os.path.join(sandbox_dir, 'X2_actions.niml.dset')\n",
    "X2 = mv.niml.read(sub_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02680659, -0.07120993, -0.03554899, ...,  0.01377774,\n",
       "       -0.02796944, -0.03744206], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(ds.samples[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, axs = plt.subplots(2, 2)\n",
    "figure, axes = plt.subplots(2,2,subplot_kw={'projection': '3d'},figsize = (12,8))\n",
    "plot_surf(fsaverage_inflated_L,np.asarray(X1.samples[0]), \n",
    "          title='X1 background attributes \\n behavior attention task\\n left hemi', \n",
    "          hemi='left', view = 'lateral', vmin=.05, vmax=.20, cmap = 'inferno',axes=axes[0][0])\n",
    "plot_surf(fsaverage_gii_L,np.asarray(X2.samples[0]), colorbar = True,\n",
    "          title='X2 background attributes \\n behavior attention task\\n left hemi', \n",
    "          hemi='left', view = 'lateral', vmin=.05, vmax=.20, cmap = 'inferno',axes=axes[0][1])\n",
    "# plot_surf(fsaverage_inflated_L,mean_cl20_taxtask_L, \n",
    "#           title='1-out-of-20 classification \\n taxonomy attention task\\n left hemi', \n",
    "#           hemi='left', view = 'lateral', vmin=.05, vmax=.20, cmap = 'inferno',axes=axes[1][0])\n",
    "# plot_surf(fsaverage_inflated_R,mean_cl20_taxtask_R, colorbar = True,\n",
    "#           title='1-out-of-20 classification \\n taxonomy attention task\\n right hemi', \n",
    "#           hemi='right', view = 'lateral', vmin=.05, vmax=.20, cmap = 'inferno',axes=axes[1][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verification - flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5290310600635536, 2.455544661025322, array(2.51188643))\n",
      "Standard transform weights for X1:\n",
      "[[0.31271817 0.085928   0.04817397 0.44378632 0.05551227]]\n",
      "[[0.3127062  0.08593173 0.0481875  0.44379273 0.05549034]]\n",
      "0.9999999977802349\n",
      "False\n",
      "Standard transform weights for X2:\n",
      "[[ 0.12628397 -0.07531208  0.19133092 -0.34598482 -0.15550639]]\n",
      "[[ 0.12626712 -0.07530233  0.19131272 -0.34596205 -0.15547659]]\n",
      "0.999999992806901\n",
      "False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5999c7247ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_x2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweights_x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_standard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution_svd_standard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambda_one_scaled, lambda_two_scaled = fit_banded_polar['spatial'].squeeze()\n",
    "ridge_scaled = fit_banded_polar['ridges'].squeeze()\n",
    "print(lambda_one_scaled, lambda_two_scaled, ridge_scaled)\n",
    "kernel_weights = fit_banded_polar['weights']\n",
    "\n",
    "Xtmp = np.c_[X1train/lambda_one_scaled, X2train/lambda_two_scaled]\n",
    "weights_standard = np.dot(Xtmp.T, kernel_weights*alpha)\n",
    "\n",
    "# Standard form solutions\n",
    "weights_x1 = weights_standard[:X1train.shape[1],:]\n",
    "weights_x2 = weights_standard[X1train.shape[1]:,:]\n",
    "\n",
    "sweights_x1 = solution_svd_standard[:X1train.shape[1],:]\n",
    "sweights_x2 = solution_svd_standard[X1train.shape[1]:,:]\n",
    "\n",
    "print('Standard transform weights for X1:')\n",
    "print(weights_x1[:1,:5])\n",
    "print(sweights_x1[:1,:5])\n",
    "print(np.corrcoef(weights_x1.ravel(), sweights_x1.ravel())[0,1])\n",
    "print(np.allclose(weights_x1, sweights_x1))\n",
    "\n",
    "print('Standard transform weights for X2:')\n",
    "print(weights_x2[:1,:5])\n",
    "print(sweights_x2[:1,:5])\n",
    "print(np.corrcoef(weights_x2.ravel(), sweights_x2.ravel())[0,1])\n",
    "print(np.allclose(weights_x2, sweights_x2))\n",
    "\n",
    "assert np.allclose(weights_standard, solution_svd_standard)\n",
    "\n",
    "\n",
    "# TIkhonov solutions\n",
    "bands = np.asarray([lambda_one_scaled]*X1train.shape[1] + [lambda_two_scaled]*X1train.shape[1])\n",
    "Cinv = np.diag(bands**-1.0)\n",
    "weights = np.dot(Cinv, weights_standard)\n",
    "\n",
    "# full eq: np.dot(np.hstack([X1/(lambda_one_scaled**2.), X2/(lambda_two_scaled**2.)]).T, kernel_weights*alpha)\n",
    "weights_x1t = weights[:X1train.shape[1],:]\n",
    "weights_x2t = weights[X1train.shape[1]:,:]\n",
    "\n",
    "tweights_x1 = solution_svd_bandstd2tik[:X1train.shape[1],:]\n",
    "tweights_x2 = solution_svd_bandstd2tik[X1train.shape[1]:,:]\n",
    "\n",
    "print('Tikhonov weights for joint model')\n",
    "print(weights_x1t[:1,:5])\n",
    "print(tweights_x1[:1,:5])\n",
    "print(np.corrcoef(weights_x1t.ravel(), tweights_x1.ravel())[0,1])\n",
    "print(weights_x2t[:1,:5])\n",
    "print(tweights_x2[:1,:5])\n",
    "print(np.corrcoef(weights_x2t.ravel(), tweights_x2.ravel())[0,1])\n",
    "\n",
    "print('Full model weights')\n",
    "print(np.corrcoef(weights.ravel(),  solution_svd_bandstd2tik.ravel())[0,1])\n",
    "assert np.allclose(weights,  solution_svd_bandstd2tik)\n",
    "print(weights.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
