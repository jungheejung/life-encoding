{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/mvpa2/base/hdf5.py:40: H5pyDeprecationWarning: The h5py.highlevel module is deprecated, code should import directly from h5py, e.g. 'from h5py import File'.\n",
      "  import h5py.highlevel  # >= 2.8.0, https://github.com/h5py/h5py/issues/1063\n",
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/pydicom/__init__.py:55: DeprecationWarning: Python 2 will no longer be supported after the pydicom v1.4 release\n",
      "  warnings.warn(msg, DeprecationWarning)\n",
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/mvpa2/testing/tools.py:81: DeprecationWarning: Importing from numpy.testing.decorators is deprecated since numpy 1.15.0, import from numpy.testing instead.\n",
      "  from numpy.testing.decorators import skipif\n",
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/_pytest/mark/structures.py:383: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/nilearn/__init__.py:73: DeprecationWarning: Python2 support is deprecated and will be removed in the next release. Consider switching to Python 3.6 or 3.7.\n",
      "  _python_deprecation_warnings()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib; matplotlib.use('agg')\n",
    "import mvpa2.suite as mv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.io import wavfile\n",
    "import sys, os, time, csv\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from nilearn.plotting import plot_surf\n",
    "import matplotlib.pyplot as plt\n",
    "from tikreg import models\n",
    "from tikreg import utils as tikutils\n",
    "\n",
    "from tikreg import models, utils as tikutils\n",
    "from tikreg import spatial_priors, temporal_priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [7., 7.]\n",
    "matplotlib.rcParams['font.size'] = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = ['sub-rid000001']\n",
    "hemispheres = ['lh']\n",
    "\n",
    "tr_movie = {1:369, 2:341, 3:372, 4:406}\n",
    "tr_fmri = {1:374, 2:346, 3:377, 4:412}\n",
    "tr_length = 2.5\n",
    "n_samples = 1509\n",
    "n_vertices = 40962\n",
    "n_proc = 32     # how many cores do we have?\n",
    "n_medial = {'lh': 3486, 'rh': 3491}\n",
    "\n",
    "# mvpa_dir = '/idata/DBIC/cara/life/pymvpa/'\n",
    "sam_data_dir = '/Users/h/Documents/projects_local/life-encoding-sandbox/data'\n",
    "# ridge_dir = '/idata/DBIC/cara/life/ridge'\n",
    "# cara_data_dir = '/idata/DBIC/cara/life/data'\n",
    "npy_dir = '/Users/h/Documents/projects_local/life-encoding-sandbox/w2v_features'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_stim_for_fold(stimfile, fold_shifted, included):\n",
    "    cam = np.load(os.path.join(npy_dir, '{0}.npy'.format(stimfile)))\n",
    "    # motion = np.load('/ihome/cara/global_motion/motion_downsampled_complete.npy')\n",
    "    #\n",
    "    # motion_list = []\n",
    "    # motion_list.append(motion[:369])\n",
    "    # motion_list.append(motion[369:710])\n",
    "    # motion_list.append(motion[710:1082])\n",
    "    # motion_list.append(motion[1082:])\n",
    "\n",
    "    full_stim = []\n",
    "    full_stim.append(cam[:369,:])\n",
    "    full_stim.append(cam[369:710,:])\n",
    "    full_stim.append(cam[710:1082,:])\n",
    "    full_stim.append(cam[1082:,:])\n",
    "\n",
    "    for i in range(len(full_stim)):\n",
    "        # m = motion_list[i]\n",
    "    \t# m_avg = np.mean(np.vstack((m[3:], m[2:-1], m[1:-2], m[:-3])),axis=0)\n",
    "    \t# m_avg = np.reshape(m_avg,(-1,1))\n",
    "\n",
    "        this = full_stim[i]\n",
    "        # full_stim[i] = np.concatenate((m_avg, this[3:,:], this[2:-1,:], this[1:-2,:], this[:-3,:]), axis=1)\n",
    "        full_stim[i] = np.concatenate((this[3:,:], this[2:-1,:], this[1:-2,:], this[:-3,:]), axis=1)\n",
    "\n",
    "    train_stim = [full_stim[i] for i in np.subtract(included, 1)]\n",
    "    test_stim = full_stim[fold_shifted-1]\n",
    "\n",
    "    return train_stim, test_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel():\n",
    "    mel_list = [[],[],[],[]]\n",
    "    directory = os.path.join(cara_data_dir, 'spectral', 'complete')\n",
    "    for f in os.listdir(directory):\n",
    "        if 'csv' in f:\n",
    "            run = int(f[-5])\n",
    "            s = pd.read_csv(os.path.join(directory, f))\n",
    "            filter_col = [col for col in s if col.startswith('mel')]\n",
    "            tr_s = np.array(s[filter_col])\n",
    "            tr_avg = np.mean(tr_s, axis=1)\n",
    "\n",
    "            groupby = tr_avg.shape[0] / tr_movie[run]\n",
    "            remainder = tr_avg.shape[0] % tr_movie[run]\n",
    "            tr_reshaped = np.reshape(tr_avg[:-remainder], (tr_movie[run], groupby))\n",
    "            avg = np.mean(tr_reshaped, axis=1)\n",
    "            mel_list[run-1] = avg\n",
    "    return mel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ws_data(test_p, fold_shifted, included, hemi):\n",
    "    print('\\nLoading fMRI GIFTI data for HA in test subj space and using {0} as test participant...'.format(test_p))\n",
    "    train_resp = []\n",
    "    for run in included:\n",
    "        avg = []\n",
    "        if run == 4:\n",
    "            resp = mv.gifti_dataset(os.path.join(sam_data_dir, '{0}_task-life_acq-{1}vol_run-0{2}.{3}.tproject.gii'.format(test_p, tr_fmri[run], run, hemi))).samples[4:-5,:]\n",
    "        else:\n",
    "            resp = mv.gifti_dataset(os.path.join(sam_data_dir, '{0}_task-life_acq-{1}vol_run-0{2}.{3}.tproject.gii'.format(test_p, tr_fmri[run], run, hemi))).samples[4:-4,:]\n",
    "\n",
    "        resp = resp[:,cortical_vertices[hemi] == 1]\n",
    "        mv.zscore(resp, chunks_attr=None)\n",
    "        print('train', run, resp.shape)\n",
    "\n",
    "        train_resp.append(resp)\n",
    "\n",
    "    if fold_shifted == 4:\n",
    "        test_resp = mv.gifti_dataset(os.path.join(sam_data_dir, '{0}_task-life_acq-{1}vol_run-0{2}.{3}.tproject.gii'.format(test_p, tr_fmri[fold_shifted], fold_shifted, hemi))).samples[4:-5,:]\n",
    "    else:\n",
    "        test_resp = mv.gifti_dataset(os.path.join(sam_data_dir, '{0}_task-life_acq-{1}vol_run-0{2}.{3}.tproject.gii'.format(test_p, tr_fmri[fold_shifted], fold_shifted, hemi))).samples[4:-4,:]\n",
    "\n",
    "    test_resp = test_resp[:,cortical_vertices[hemi] == 1]\n",
    "    mv.zscore(test_resp, chunks_attr=None)\n",
    "    print('test', fold_shifted, test_resp.shape)\n",
    "\n",
    "    return train_resp, test_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'visual'\n",
    "align = 'ws'\n",
    "# stimfile = 'all'\n",
    "fold = 1\n",
    "fold_shifted = fold+1\n",
    "hemi = 'lh'\n",
    "included = [1,2,3,4]\n",
    "included.remove(fold_shifted)\n",
    "test_p = 'sub-rid000001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/mvpa2/support/nibabel/afni_niml.py:182: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  data_1d = np.fromstring(s, dtype=tp)\n"
     ]
    }
   ],
   "source": [
    "cortical_vertices = {}\n",
    "for half in ['lh', 'rh']:\n",
    "    test_ds = mv.niml.read('/Users/h/Documents/projects_local/life-encoding-sandbox/niml/ws.lh.niml.dset'.format(half))\n",
    "    cortical_vertices[half] = np.ones((n_vertices))\n",
    "    cortical_vertices[half][np.sum(test_ds.samples[1:, :] != 0, axis=0) == 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features bg & action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading fMRI GIFTI data for HA in test subj space and using sub-rid000001 as test participant...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/mvpa2/datasets/gifti.py:77: DeprecationWarning: giftiio.read function deprecated. Use nibabel.load() instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  samples = giftiio.read(samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train', 1, (366, 37476))\n",
      "('train', 3, (369, 37476))\n",
      "('train', 4, (403, 37476))\n",
      "('test', 2, (338, 37476))\n"
     ]
    }
   ],
   "source": [
    "stimfile = 'bg'\n",
    "X1train_stim, X1test_stim = get_visual_stim_for_fold('{0}_{1}'.format(model, stimfile), fold_shifted, included)\n",
    "\n",
    "stimfile = 'actions'\n",
    "X2train_stim, X2test_stim = get_visual_stim_for_fold('{0}_{1}'.format(model, stimfile), fold_shifted, included)\n",
    "\n",
    "Ytrain_uncon, Ytest = get_ws_data(test_p, fold_shifted, included, hemi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1138, 1200), 'X1train')\n",
      "((1138, 1200), 'X2train')\n",
      "((338, 1200), 'X1test_stim')\n",
      "((338, 1200), 'X2test_stim')\n",
      "((338, 37476), 'Ytest')\n",
      "((1138, 37476), 'Ytrain')\n"
     ]
    }
   ],
   "source": [
    "# concatenate 3 runs\n",
    "X1train = np.concatenate(X1train_stim)\n",
    "X2train = np.concatenate(X2train_stim)\n",
    "\n",
    "Ytrain = np.concatenate(Ytrain_uncon)\n",
    "\n",
    "print(X1train.shape, \"X1train\" )\n",
    "print(X2train.shape, \"X2train\")\n",
    "print(X1test_stim.shape, \"X1test_stim\")\n",
    "print(X2test_stim.shape, \"X2test_stim\")\n",
    "print(Ytest.shape, \"Ytest\")\n",
    "print(Ytrain.shape, \"Ytrain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part where I'm stuck: loro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = np.arange(X1train.shape[0]).tolist()\n",
    "dur1, dur2, dur3 = tr_movie[included[0]]-3, tr_movie[included[1]]-3,tr_movie[included[2]]-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1train.shape[0] #366+369+403"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version 1\n",
    "* Error: # AttributeError: 'list' object has no attribute 'reshape'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loro1 = [ (train_id[:dur1+dur2], train_id[dur1+dur2:]),                      \n",
    "       ( list(np.concatenate((train_id[:dur1],train_id[dur1+dur2:]),axis=0)),\n",
    "         train_id[dur1:dur1+dur2]),                                           \n",
    "        (train_id[dur1:], train_id[:dur1])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loro first pair test: 735\n",
      "loro first pair val: 403\n"
     ]
    }
   ],
   "source": [
    "print(\"loro first pair test: %s\\nloro first pair val: %s\" % (len(loro1[0][0]), len(loro1[0][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version 2\n",
    "* error: operands could not be broadcast together with shapes (882000,1) (735,1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loro2 = [ (X1train[:dur1+dur2], X1train[dur1+dur2:]),                      \n",
    "       ( list(np.concatenate((X1train[:dur1],X1train[dur1+dur2:]),axis=0)),\n",
    "         X1train[dur1:dur1+dur2]),                                           \n",
    "        (X1train[dur1:], X1train[:dur1])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loro first pair test: (735, 1200)\n",
      "loro first pair val: (403, 1200)\n"
     ]
    }
   ],
   "source": [
    "print(\"loro first pair test: %s\\nloro first pair val: %s\" % (loro2[0][0].shape, loro2[0][1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06799316,  0.10040283,  0.07690811, ...,  0.02330017,\n",
       "         0.04455566, -0.12078857],\n",
       "       [ 0.06799316,  0.10040283,  0.07690811, ...,  0.02330017,\n",
       "         0.04455566, -0.12078857],\n",
       "       [ 0.06799316,  0.10040283,  0.07690811, ...,  0.02330017,\n",
       "         0.04455566, -0.12078857],\n",
       "       ...,\n",
       "       [ 0.037407  ,  0.11371806, -0.00154876, ..., -0.01376162,\n",
       "         0.11535781,  0.00118444],\n",
       "       [ 0.037407  ,  0.11371806, -0.00154876, ..., -0.01376162,\n",
       "         0.11535781,  0.00118444],\n",
       "       [ 0.037407  ,  0.11371806, -0.00154876, ..., -0.01376162,\n",
       "         0.11535781,  0.00118444]], dtype=float32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loro2[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version 3\n",
    "* operands could not be broadcast together with shapes (882000,1) (735,1200) 'safe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loro3 = [ (np.concatenate((X1train_stim[0],X1train_stim[1]), axis = 0), X1train_stim[2]),\n",
    "    (np.concatenate((X1train_stim[0],X1train_stim[2]), axis = 0), X1train_stim[1]),\n",
    "    (np.concatenate((X1train_stim[1],X1train_stim[2]), axis = 0), X1train_stim[0]) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loro first pair test: (735, 1200)\n",
      "loro first pair val: (403, 1200)\n"
     ]
    }
   ],
   "source": [
    "print(\"loro first pair test: %s\\nloro first pair val: %s\" % (loro3[0][0].shape, loro3[0][1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loro check - https://github.com/gallantlab/tikreg/blob/master/tikreg/models.py line 642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37476"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(735, 403)\n",
      "train ridge fold  1/3: ntrain=735, nval=403\n",
      "(769, 369)\n",
      "train ridge fold  2/3: ntrain=769, nval=369\n",
      "(772, 366)\n",
      "train ridge fold  3/3: ntrain=772, nval=366\n"
     ]
    }
   ],
   "source": [
    "for fdx,fold in enumerate(loro):\n",
    "    trn,val = fold\n",
    "    ntrn,nval = len(trn),len(val)\n",
    "    print(ntrn,nval)\n",
    "    txt = (fdx+1,3,ntrn,nval)\n",
    "    print('train ridge fold  %i/%i: ntrain=%i, nval=%i'%txt)\n",
    "    \n",
    "#     Ktrn = tikutils.fast_indexing(X1train, trn, trn)\n",
    "#     Kval = tikutils.fast_indexing(X1train, val, trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(882000, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tikreg - one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77.84183577448114, 4.6415888336127775, 2.51188643150958, 0.5290310600635536, 2.455544661025322)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sampling in terms of ratios and scalings\n",
    "alphas = np.logspace(0,4,11)\n",
    "ratios = np.logspace(-2,2,25)\n",
    "\n",
    "# Solve for one hyperparameter set only\n",
    "# We will use this solution to test the tikreg implementation\n",
    "ratio = ratios[16]\n",
    "alpha = alphas[1]\n",
    "\n",
    "angle = np.arctan(ratio)\n",
    "lambda_one = np.cos(angle)*alpha\n",
    "lambda_two = np.sin(angle)*alpha\n",
    "\n",
    "\n",
    "bands = np.asarray([lambda_one]*X1train.shape[1] + [lambda_two]*X2train.shape[1])\n",
    "Cinv = np.diag(bands**-1)\n",
    "\n",
    "A = np.hstack([X1train/lambda_one, X2train/lambda_two])\n",
    "U, S, VT = np.linalg.svd(A, full_matrices=False)\n",
    "V = VT.T\n",
    "UTY = np.dot(U.T, Ytrain)\n",
    "D = np.diag(S / (S**2 + alpha**2))\n",
    "\n",
    "solution_svd_standard = np.linalg.multi_dot([V, D, UTY])*alpha\n",
    "solution_svd_bandstd2tik = np.dot(Cinv, solution_svd_standard)\n",
    "\n",
    "print(np.rad2deg(angle), ratio, alpha, lambda_one, lambda_two)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1: temporal 1/1=0.000, features 1/1=(0.2106, 0.9776)\n",
      "pop.cv.best:  2.512, mean=0.2046, (25,50,75)pctl=(0.1580,0.2001,0.2464),(0.0<r>0.5): (37468,000)\n",
      "Duration 0.0629[mins]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/tikreg/models.py:1222: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  unique_optima = np.vstack(set(tuple(row) for row in optima)) # get unique rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37476 responses: ridge=    2.512, temporal=0.000, spatial=(0.211, 0.978) perf=0.0067\n",
      "Total duration 0.1392[mins]\n"
     ]
    }
   ],
   "source": [
    "# Use tikreg to find the solution\n",
    "X1_prior = spatial_priors.SphericalPrior(X1train, hyparams=[lambda_one])\n",
    "X2_prior = spatial_priors.SphericalPrior(X2train, hyparams=[lambda_two])\n",
    "# A temporal prior is unnecessary, so we specify no delays\n",
    "temporal_prior = temporal_priors.SphericalPrior(delays=[0]) # no delays\n",
    "\n",
    "fit_banded_polar = models.estimate_stem_wmvnp(features_train=[X1train, X2train], \n",
    "                                              responses_train=Ytrain,\n",
    "                                              features_test=[X1test_stim, X2test_stim],\n",
    "                                              responses_test=Ytest,\n",
    "                                              feature_priors=[X1_prior, X2_prior],\n",
    "                                              temporal_prior=temporal_prior,\n",
    "                                              ridges=[alpha],\n",
    "                                              folds= (1,5), # 1x 5-fold cross-validation\n",
    "                                              performance=True,\n",
    "                                              normalize_hyparams=True,\n",
    "                                              weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37476, 4)\n"
     ]
    }
   ],
   "source": [
    "voxelwise_optimal_hyperparameters = fit_banded_polar['optima']\n",
    "print(voxelwise_optimal_hyperparameters.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loro - estimate_stem_wmvnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1: temporal 1/1=0.000, features 1/1=(0.2106, 0.9776)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-07ce96685bf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                                               \u001b[0mperformance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                               \u001b[0mnormalize_hyparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                               weights=True)\n\u001b[0m",
      "\u001b[0;32m/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/tikreg/models.pyc\u001b[0m in \u001b[0;36mestimate_stem_wmvnp\u001b[0;34m(features_train, responses_train, features_test, responses_test, ridges, normalize_hyparams, normalize_kernel, temporal_prior, feature_priors, weights, predictions, performance, folds, method, verbosity, cvresults, population_optimal, keep_cvfolds, chunklen, metric)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                                         \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                                         \u001b[0mchunklen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunklen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m                                         \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m                                         )\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/tikreg/models.pyc\u001b[0m in \u001b[0;36mcrossval_stem_wmvnp\u001b[0;34m(features_train, responses_train, ridges, temporal_prior, feature_priors, population_mean, folds, method, verbosity, chunklen, kernel_features, normalize_kernel, normalize_hyparams, metric, zscore_ytrain, zscore_yval, weights, predictions)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;31m# extract training and validation sets from full kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             \u001b[0mktrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtikutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrnidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrnidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0mkval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtikutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrnidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0msample_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/tikreg/utils.pyc\u001b[0m in \u001b[0;36mfast_indexing\u001b[0;34m(a, rows, cols)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# Use tikreg to find the solution\n",
    "X1_prior = spatial_priors.SphericalPrior(X1train, hyparams=[lambda_one])\n",
    "X2_prior = spatial_priors.SphericalPrior(X2train, hyparams=[lambda_two])\n",
    "# A temporal prior is unnecessary, so we specify no delays\n",
    "temporal_prior = temporal_priors.SphericalPrior(delays=[0]) # no delays\n",
    "\n",
    "fit_banded_polar = models.estimate_stem_wmvnp(features_train=[X1train, X2train], \n",
    "                                              responses_train=Ytrain,\n",
    "                                              features_test=[X1test_stim, X2test_stim],\n",
    "                                              responses_test=Ytest,\n",
    "                                              feature_priors=[X1_prior, X2_prior],\n",
    "                                              temporal_prior=temporal_prior,\n",
    "                                              ridges=[alpha],\n",
    "                                              folds= loro1, # 1x 5-fold cross-validation\n",
    "                                              performance=True,\n",
    "                                              normalize_hyparams=True,\n",
    "                                              weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loro - cvridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting *1* ridges, across *3* folds, and *1* \"linear\" kernel parameters\n",
      "Caching *linear* kernel\n",
      "Updating *linear* kernel 1/1:None\n",
      "train ridge fold  1/3: ntrain=735, nval=403\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (882000,1) (735,1200) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-f01ce2c66dca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                                               \u001b[0mperformance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                               \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                  )\n",
      "\u001b[0;32m/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/tikreg/models.pyc\u001b[0m in \u001b[0;36mcvridge\u001b[0;34m(Xtrain, Ytrain, Xtest, Ytest, ridges, Li, kernel_name, kernel_params, folds, nfolds, blocklen, trainpct, verbose, EPS, withinset_test, performance, predictions, weights, kernel_weights, yzscore, population_optimum, metric)\u001b[0m\n\u001b[1;32m    659\u001b[0m                                       )\n\u001b[1;32m    660\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m                 \u001b[0mKtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtikutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m                 \u001b[0mKval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtikutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                 res = solve_l2_dual(Ktrain,\n",
      "\u001b[0;32m/Users/h/anaconda3/envs/pymvpa_env/lib/python2.7/site-packages/tikreg/utils.pyc\u001b[0m in \u001b[0;36mfast_indexing\u001b[0;34m(a, rows, cols)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (882000,1) (735,1200) "
     ]
    }
   ],
   "source": [
    "# Use tikreg to find the solution\n",
    "X1_prior = spatial_priors.SphericalPrior(X1train, hyparams=[lambda_one])\n",
    "X2_prior = spatial_priors.SphericalPrior(X2train, hyparams=[lambda_two])\n",
    "# A temporal prior is unnecessary, so we specify no delays\n",
    "temporal_prior = temporal_priors.SphericalPrior(delays=[0]) # no delays\n",
    "\n",
    "fit_banded_polar = models.cvridge(X1train, Ytrain,\n",
    "                                              X1test_stim,Ytest,\n",
    "#                                               feature_priors=[X1_prior, X2_prior],\n",
    "#                                               temporal_prior=temporal_prior,\n",
    "                                              ridges=[alpha],\n",
    "                                              folds= loro3, # 1x 5-fold cross-validation\n",
    "                                              performance=True,\n",
    "                                              weights=True, \n",
    "                                  predictions = True\n",
    "                                  \n",
    "                                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
